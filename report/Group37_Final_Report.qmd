---
title: "Harmony Through Numbers: Classifying Spotify Data Across Genres and Decades "
subtitle: "DSAN 5300 Final Project - Group 37"
authors: ["Jorge Bris Moreno", "William McGloin", "Kangheng Liu", "Isfar Baset"]
date: last-modified
date-format: long
format:
  html:
    self-contained: true
    toc: true
    code-overflow: wrap
    code-fold: true
---

# Introduction
In this project, our group endeavors to bridge the gap between music and data science by employing Spotify's extensive datasets to perform assorted classification tasks. Using various metrics provided by Spotify, such as danceability, energy, and loudness, we aimed to categorize music into genres and decades. Our goal was to implement sophisticated data analysis techniques learned in class to perform classification at both the artist and track levels. This project explores the feasibility of such classifications and tests the effectiveness of different machine-learning models in handling uniquely complex data like music.

# Our Data
To tackle this project, we utilized the spotifyr package to extract data for the top 50 artists across ten popular genres, resulting in an initial dataset that included over 400 artists. We then expanded our dataset by extracting every track for these artists, although we had to clean and preprocess the data due to duplicates and corrupted information. This process left us with a final dataset comprising approximately 50,000 tracks from roughly 400 artists. Additionally, we introduced a new variable, 'decade,' by binning song release dates, which was crucial for our subsequent temporal analysis.

# Exploratory Data Analysis
![](../images/decade_distribution.png)

The above graph displays the number of tracks in each decade within our dataset. One can see that there is a severely imbalanced distribution, with many newer songs. To address this problem, we used various sampling methods to balance the training data for our models.

![](../images/heatmap_transparent.png)

This heat map allows us to explore values of the assorted metrics, compare them between genres, and gain a better understanding the various distributions. With many of the metrics having similar values across genres, classification becomes a harder task. 

# Methodology
Our methodology involved several key steps: data aggregation, cleaning, and establishing classification labels. For artist-level data, we averaged the Spotify metrics to create a singular profile per artist, assuming a consistent style across their work. For genre classification, we started with multiple genres per artist but narrowed it down to one primary genre due to significant overlap and the limitations of our dataset size. We applied various machine learning models—logistic regression, support vector machines, neural networks, random forests, and XGBoost, all with hyperparameter tuning—to predict genres and decades, adapting our approach based on the peculiarities of each dataset level (artist vs. track).

# ML Methods
We employed a variety of machine learning models to tackle the classification tasks, each chosen for its unique strengths in handling complex patterns within large datasets:

1.	Logistic Regression: A straightforward yet powerful model used primarily for binary classification. For our multi-class classification tasks, we utilized the One-vs-Rest (OVR) strategy to extend logistic regression's capabilities.
2.	Support Vector Machines (SVMs): These models are effective in high-dimensional spaces and can define complex boundaries with kernel functions, making them suitable for our genre classification problem.
3.	Neural Networks: With their deep learning capabilities, neural networks are adept at capturing nonlinear relationships and interactions between features, making them ideal for processing the intricate properties of musical data.
4.	Random Forests: This ensemble learning method uses multiple decision trees to improve classification accuracy and control over-fitting. It is particularly good at handling varied data types and large datasets, providing robustness and reliability.
5.	XGBoost (Extreme Gradient Boosting): An implementation of gradient-boosted decision trees designed for speed and performance, XGBoost is renowned for its efficiency in classification tasks and feature handling, making it a strong candidate for genre and decade classification.

Each model was rigorously tuned with hyperparameters to optimize performance, ensuring that our classifications were accurate and reflected the underlying data complexities.

# Classification: Genre

In our project, we implemented two distinct strategies for our genre classification tasks. The first approach involved classifying music artists into various genres based on a range of features and datasets specifically about the artists. The second strategy was aimed at identifying the genre of music tracks themselves, using the distinct characteristics and features of the tracks. Each method utilized tailored datasets and features, appropriate for classifying either at the artist level or the track level, to achieve accurate genre categorization.

## Artist Level Genre Clasification

### Data Setup 

In the initial steps of our project, we utilized essential Python libraries, such as `numpy` and `pandas`, which are crucial for numerical operations and data manipulation respectively. We loaded our primary dataset, `artists.csv`, into a pandas DataFrame. This dataset contains detailed information about music artists, including their names and associated genres. An immediate examination of the dataset provided an understanding of its structure, which includes various columns critical to our analysis.

### Data Exploration and Cleansing

During our data exploration phase, we identified rows where the genre information was missing key data for our genre classification model. Specific corrections included rectifying genre assignments for artists like "The Beach Boys" and removing entries which deemed irrelevant, such as "Roger Miller". This cleansing step ensured the accuracy and reliability of our dataset, setting a solid foundation for further analysis and modeling.

### Integration and Processing of Genre-Specific Data

To enhance our dataset and refine our artist-level genre classification approach, we integrated additional genre-specific datasets. These datasets, representing genres such as country, rock, and hip-hop were utilized to assign rankings to artists based on their popularity or influence within those genres. These rankings are crucial for determining the primary genre of artists associated with multiple genres, providing a more nuanced and quantitative approach to our analysis.

### Genre Classification Logic

We established a robust methodology for determining an artist's primary genre. By leveraging the ranking system developed from genre-specific datasets, we created a function capable of comparing an artist's rank across different genres. This function identifies the genre in which an artist has the highest ranking as their primary genre. It also includes logic to handle cases where an artist's primary genre is not very obvious, marking these instances for further review. This ensures that our genre classifications are as accurate and reflective of the data as possible.

### Feature Engineering and Data Integration

Following the classification logic, extensive feature engineering and the integration of additional data sources were conducted. We updated our main DataFrame by applying the primary genre determination, ensuring each artist's record was accurately reflected. Additional features that could influence genre classification, such as historical data trends and artist-specific metrics, were also merged. This comprehensive approach to data preparation prepared our dataset for effective machine learning applications.

### Machine Learning Preparation

We prepared our dataset for machine learning by splitting it into training and test sets—a standard practice to evaluate a model's performance on unseen data. We also converted categorical variables into a numerical format using techniques such as one-hot encoding. These transformations are crucial for training machine learning models that require numerical input, setting the stage for robust model training.

### Model Training and Evaluation

In this section of our project, we evaluated several machine learning models in order to determine the most effective approach for classifying music genres based on artist data. Each model was assessed based on its accuracy and computation time which are both crucial factors in practical applications. Below is a summary of the outcomes for each model:

#### Logistic Regression
- **Test Accuracy**: 81.03%
- **Computation Time**: 3.2 seconds
- **Comments**: Logistic Regression provided a robust balance between speed and accuracy, proving to be highly efficient for scenarios where prompt results are necessary without a significant compromise on performance.

#### Support Vector Machine (SVM)
- **Test Accuracy**: 77.59%
- **Computation Time**: 3.4 seconds
- **Comments**: SVM displayed slightly lower accuracy compared to Logistic Regression and had a comparable speed. It's generally well-suited for linearly separable data but showed moderate performance in our multi-class classification task.

#### Neural Network
- **Train Accuracy**: 68.85%
- **Test Accuracy**: 70.69%
- **Computation Time**: 11 minutes 46.2 seconds
- **Comments**: The Neural Network required considerably more time to train and yielded lower accuracy. This model may benefit from further tuning of hyperparameters or adjustments in the network architecture to enhance its efficacy.

#### Random Forest
- **Test Accuracy**: 79.31%
- **Computation Time**: 1 minute 6.4 seconds
- **Comments**: Random Forest achieved good accuracy, suggesting effective handling of the diverse and feature-rich data through its ensemble method. The computational time was reasonable for an ensemble approach, making it a strong contender.

#### XGBoost
- **Test Accuracy**: 77.59%
- **Computation Time**: 24.5 seconds
- **Comments**: XGBoost is well-known for its high performance in structured data problems. Here it offered competitive accuracy with SVM but required longer training time. Its capability to manage various data structures efficiently makes it a valuable model despite the higher computational cost.


### Hyperparameter Tuning

We implemented a grid search to fine tune the model's hyperparameters and optimize its performance. This was crucial in identifying the most effective model settings for our specific dataset and artist based genre classification task. The best parameters were then re-evaluated using the test set to confirm the model's improved accuracy and predictive capabilities. The results provided a definitive assessment of our model's performance and its ability to generalize on new data.

### Conclusion

The genre classification at the artist level proved to be quite successful, routinely achieving test accuracies over 75%, with logistic regression peaking at 81%. This was significantly higher than a baseline model of random guessing, indicative of the effectiveness of our feature selection and machine learning techniques. 

## Track Level Genre Classification

### Data Setup

In this initial phase, we loaded essential Python libraries necessary for our analysis: `numpy` for numerical operations and `pandas` for data manipulation. We then proceeded to load our primary dataset from `tracks.csv`, which encompasses detailed information about music tracks, including artist names and associated genres. A preliminary review of the dataset helped us understand its structure, critical for our downstream analysis.

### Data Cleaning and Preprocessing

Data quality is paramount, hence we performed rigorous cleaning and preprocessing of our dataset. This included handling missing values, particularly in the genre column, and removing anomalies. We adjusted data types for better computational efficiency and prepared categorical data for future machine learning processes.


### Model Training and Evaluation

In this phase, we trained and evaluated several machine learning models to classify tracks into genres. Each model's performance was assessed based on accuracy and computation time. Here is a summary of how each model performed:

#### Logistic Regression
- **Test Accuracy**: 51.38%
- **Computation Time**: 6 minutes 3.89 seconds

#### Support Vector Machine (SVM)
- **Test Accuracy**: 54.89%
- **Computation Time**: 80 minutes 4.4 seconds

#### Neural Network
- **Train Accuracy**: 54.45%
- **Test Accuracy**: 49.18%
- **Computation Time**: Approximately 44 minutes

#### Random Forest
- **Test Accuracy**: 61.68%
- **Computation Time**: 46 minutes 49.8 seconds

#### XGBoost
- **Test Accuracy**: 63.03%
- **Computation Time**: 2 minutes 51.4 seconds

### Conclusion
The track-level genre classification performed less optimally due to the inherent variability in songs by the same artist, peaking at 63% accuracy with XGBoost.

# Classification: Decade
Decade classification posed a more significant challenge, primarily due to the imbalanced nature of our data—most tracks were from recent decades. After downsampling to even out the class distribution for the training data, we achieved modest accuracies of around 38%, with random forests and XGBoost being the top performers. Notably, when we filtered the dataset to include only rock genre tracks, the accuracy improved, suggesting genre-specific characteristics can significantly influence the success of decade classification.

![](../images/decade_feature_importance.png)

The Random Forest Classifier provides insights into which variables most significantly impact the determination of a track's decade, highlighting the notable changes over time. Additionally, the plot above also allows for the comparison of various models' accuracies and runtimes. While these models aren't highly accurate, they notably outperform a random classifier, doubling accuracy in some instances.

# Conclusion
Our findings demonstrate a promising but challenging path forward in classifying music data. While we achieved notable success in classifying artists into genres, decade classification could have performed better, highlighting the complexity of temporal influences in music. The variability within an artist's work across different songs suggests a potential for future research to refine track-level classifications. Overall, this project underscores the potential of machine learning in transforming our understanding of music through data, opening avenues for deeper exploration into the analytics of sound.

# Recommendations
Based on our project's findings and the challenges we encountered, we recommend the following strategies for future projects in music classification using machine learning:

1.	Expand Data Collection: To enhance the models' generalizability, future projects should consider expanding the dataset to include a more diverse array of artists and tracks from additional genres and less represented decades. This expansion is crucial for mitigating issues related to data imbalances and providing a richer basis for classification.
2.	Refine Data Labeling Techniques: In our project, track-level genre data was unavailable, necessitating the use of an artist's primary genre to label their songs. Further research could help investigate how an artist's style changes over time, possibly incorporating more granular and dynamic labeling methods that reflect these evolutions.
3.	Utilize Unsupervised Learning: Unsupervised learning techniques such as clustering could be explored to better understand the underlying structure of the data and identify patterns without predefined labels. This approach might also uncover interesting insights about genre and decade classifications that are not immediately apparent.

By addressing these recommendations, future projects can build on our work's foundation and push the boundaries of what's possible at the intersection of data science and music analysis.
