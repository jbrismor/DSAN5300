---
title: "Harmony Through Numbers: Classifying Spotify Data Across Genres and Decades "
subtitle: "DSAN 5300 Final Project - Group 37"
authors: ["Jorge Bris Moreno", "William McGloin", "Kangheng Liu", "Isfar Baset"]
date: last-modified
date-format: long
format:
  html:
    self-contained: true
    toc: true
    code-overflow: wrap
    code-fold: true
---

# Introduction
In this project, our group endeavors to bridge the gap between music and data science by employing Spotify's extensive datasets to perform assorted classification tasks. Using various metrics provided by Spotify, such as danceability, energy, and loudness, we aimed to categorize music into genres and decades. Our goal was to implement sophisticated data analysis techniques learned in class to perform classification at both the artist and track levels. This project explores the feasibility of such classifications and tests the effectiveness of different machine-learning models in handling uniquely complex data like music.

# Our Data
To tackle this project, we utilized the spotifyr package to extract data for the top 50 artists across ten popular genres, resulting in an initial dataset that included over 400 artists. We then expanded our dataset by extracting every track for these artists, although we had to clean and preprocess the data due to duplicates and corrupted information. This process left us with a final dataset comprising approximately 50,000 tracks from roughly 400 artists. Additionally, we introduced a new variable, 'decade,' by binning song release dates, which was crucial for our subsequent temporal analysis.

# Exploratory Data Analysis
![](../images/decade_distribution.png)

The above graph displays the number of tracks in each decade within our dataset. One can see that there is a severely imbalanced distribution, with many newer songs. To address this problem, we used various sampling methods to balance the training data for our models.

![](../images/heatmap_transparent.png)

This heat map allows us to explore values of the assorted metrics, compare them between genres, and gain a better understanding the various distributions. With many of the metrics having similar values across genres, classification becomes a harder task. 

# Methodology
Our methodology involved several key steps: data aggregation, cleaning, and establishing classification labels. For artist-level data, we averaged the Spotify metrics to create a singular profile per artist, assuming a consistent style across their work. For genre classification, we started with multiple genres per artist but narrowed it down to one primary genre due to significant overlap and the limitations of our dataset size. We applied various machine learning models—logistic regression, support vector machines, neural networks, random forests, and XGBoost, all with hyperparameter tuning—to predict genres and decades, adapting our approach based on the peculiarities of each dataset level (artist vs. track).

# ML Methods
We employed a variety of machine learning models to tackle the classification tasks, each chosen for its unique strengths in handling complex patterns within large datasets:

1.	Logistic Regression: A straightforward yet powerful model used primarily for binary classification. For our multi-class classification tasks, we utilized the One-vs-Rest (OVR) strategy to extend logistic regression's capabilities.
2.	Support Vector Machines (SVMs): These models are effective in high-dimensional spaces and can define complex boundaries with kernel functions, making them suitable for our genre classification problem.
3.	Neural Networks: With their deep learning capabilities, neural networks are adept at capturing nonlinear relationships and interactions between features, making them ideal for processing the intricate properties of musical data.
4.	Random Forests: This ensemble learning method uses multiple decision trees to improve classification accuracy and control over-fitting. It is particularly good at handling varied data types and large datasets, providing robustness and reliability.
5.	XGBoost (Extreme Gradient Boosting): An implementation of gradient-boosted decision trees designed for speed and performance, XGBoost is renowned for its efficiency in classification tasks and feature handling, making it a strong candidate for genre and decade classification.

Each model was rigorously tuned with hyperparameters to optimize performance, ensuring that our classifications were accurate and reflected the underlying data complexities.

# Classification: Genre

In our project, we implemented two distinct strategies for our genre classification tasks. The first approach involved classifying music artists into various genres based on a range of features and datasets specifically about the artists. The second strategy was aimed at identifying the genre of music tracks themselves, using the distinct characteristics and features of the tracks. Each method utilized tailored datasets and features, appropriate for classifying either at the artist level or the track level, to achieve accurate genre categorization.

## Artist Level Genre Clasification

### Data Setup 

In the initial steps of our project, we utilized essential Python libraries, such as `numpy` and `pandas`, which are crucial for numerical operations and data manipulation respectively. We loaded our primary dataset, `artists.csv`, into a pandas DataFrame. This dataset contains detailed information about music artists, including their names and associated genres. An immediate examination of the dataset provided an understanding of its structure, which includes various columns critical to our analysis.

### Data Exploration and Cleansing

During our data exploration phase, we identified rows where the genre information was missing key data for our genre classification model. Specific corrections included rectifying genre assignments for artists like "The Beach Boys" and removing entries which deemed irrelevant, such as "Roger Miller". This cleansing step ensured the accuracy and reliability of our dataset, setting a solid foundation for further analysis and modeling.

### Integration and Processing of Genre-Specific Data

To enhance our dataset and refine our artist-level genre classification approach, we integrated additional genre-specific datasets. These datasets, representing genres such as country, rock, and hip-hop were utilized to assign rankings to artists based on their popularity or influence within those genres. These rankings are crucial for determining the primary genre of artists associated with multiple genres, providing a more nuanced and quantitative approach to our analysis.

### Genre Classification Logic

We established a robust methodology for determining an artist's primary genre. By leveraging the ranking system developed from genre-specific datasets, we created a function capable of comparing an artist's rank across different genres. This function identifies the genre in which an artist has the highest ranking as their primary genre. It also includes logic to handle cases where an artist's primary genre is not very obvious, marking these instances for further review. This ensures that our genre classifications are as accurate and reflective of the data as possible.

### Feature Engineering and Data Integration

Following the classification logic, extensive feature engineering and the integration of additional data sources were conducted. We updated our main DataFrame by applying the primary genre determination, ensuring each artist's record was accurately reflected. Additional features that could influence genre classification, such as historical data trends and artist-specific metrics, were also merged. This comprehensive approach to data preparation prepared our dataset for effective machine learning applications.

### Machine Learning Preparation

We prepared our dataset for machine learning by splitting it into training and test sets which is a standard practice to evaluate a model's performance on unseen data. We also converted categorical variables into a numerical format using techniques such as one-hot encoding. These transformations are crucial for training machine learning models that require numerical input, setting the stage for robust model training.

### Model Training and Evaluation

In this section of our project, we evaluated several machine learning models in order to determine the most effective approach for classifying music genres based on artist data. Each model was assessed based on its accuracy and computation time which are both crucial factors in practical applications. Below is a summary of the outcomes for each model:

#### Logistic Regression
- **Test Accuracy**: 81.03%
- **Computation Time**: 3.2 seconds
- **Comments**: Logistic Regression provided a robust balance between speed and accuracy, proving to be highly efficient for scenarios where prompt results are necessary without a significant compromise on performance.

#### Support Vector Machine (SVM)
- **Test Accuracy**: 77.59%
- **Computation Time**: 3.4 seconds
- **Comments**: SVM displayed slightly lower accuracy compared to Logistic Regression and had a comparable speed. It's generally well-suited for linearly separable data but showed moderate performance in our multi-class classification task.

#### Neural Network
- **Train Accuracy**: 68.85%
- **Test Accuracy**: 70.69%
- **Computation Time**: 11 minutes 46.2 seconds
- **Comments**: The Neural Network required considerably more time to train and yielded lower accuracy. This model may benefit from further tuning of hyperparameters or adjustments in the network architecture to enhance its efficacy.

#### Random Forest
- **Test Accuracy**: 79.31%
- **Computation Time**: 1 minute 6.4 seconds
- **Comments**: Random Forest achieved good accuracy, suggesting effective handling of the diverse and feature-rich data through its ensemble method. The computational time was reasonable for an ensemble approach, making it a strong contender.

#### XGBoost
- **Test Accuracy**: 77.59%
- **Computation Time**: 24.5 seconds
- **Comments**: XGBoost is well-known for its high performance in structured data problems. Here it offered competitive accuracy with SVM but required longer training time. Its capability to manage various data structures efficiently makes it a valuable model despite the higher computational cost.


### Hyperparameter Tuning

We implemented a grid search to fine tune the model's hyperparameters and optimize its performance. This was crucial in identifying the most effective model settings for our specific dataset and artist based genre classification task. The best parameters were then re-evaluated using the test set to confirm the model's improved accuracy and predictive capabilities. The results provided a definitive assessment of our model's performance and its ability to generalize on new data.

### Conclusion

The genre classification at the artist level proved to be quite successful, routinely achieving test accuracies over 75%, with logistic regression peaking at 81%. This was significantly higher than a baseline model of random guessing, indicative of the effectiveness of our feature selection and machine learning techniques. 

## Track Level Genre Classification

### Data Setup

We imported necessary Python libraries such as `numpy` and `pandas`, essential for handling large datasets and numerical computations. The primary dataset, `tracks.csv`, was loaded into a pandas DataFrame. This dataset contains detailed attributes of music tracks such as danceability, energy, loudness, and other features that describe the audio characteristics of the tracks.

### Data Cleaning and Preprocessing

Initial data cleaning involved handling missing values, especially in the genre column, which is crucial for our classification task. We also discarded any data points considered irrelevant or redundant to avoid skewing our results and impairing our models' efficiency. This cleaning step ensured a more focused and efficient dataset ready for the subsequent stages of our analysis.

### Integration and Processing of Genre-Specific Data

By integrating `genre_of_artists.csv` with our track data, we linked each track with its corresponding artist's genre, thereby enriching our dataset with essential classification labels. This integration not only streamlined the data but also enriched it, providing a solid foundation for accurate genre classification.

### Genre Classification Logic

The classification strategy revolved around the application of several machine learning models. Each model was evaluated based on its ability to accurately predict genres from track features. The logic also included strategies for handling multi-genre classifications and discrepancies in genre labeling.

### Feature Engineering and Data Integration

We conducted feature engineering as well, which included encoding categorical variables, normalizing numerical values, and creating new features that could provide more insights into the genre classification. Features derived from the `key_mode` column, such as musical key and mode, were particularly significant, as these musical aspects are often strong indicators of genre.

### Machine Learning Preparation

The prepared dataset was split into training and test sets to validate the effectiveness of the models. This step is critical in assessing how well our model performs on new unseen data and ensuring that we gauge its real-world applicability accurately.


### Model Training and Evaluation

Here we trained and evaluated several machine learning models to classify tracks into genres. Each model's performance was assessed based on accuracy and computation time. Below is a summary of how each model performed:

#### Logistic Regression
- **Test Accuracy**: 51.38%
- **Computation Time**: 6m 3.89s

#### Support Vector Machine (SVM)
- **Test Accuracy**: 54.89%
- **Computation Time**: 80m 4.4s

#### Neural Network
- **Train Accuracy**: 54.45%
- **Test Accuracy**: 49.18%
- **Computation Time**: 44m

#### Random Forest
- **Test Accuracy**: 61.68%
- **Computation Time**: 46m 49.8s

#### XGBoost
- **Test Accuracy**: 63.03%
- **Computation Time**: 2m 51.4s

### Hyperparameter Tuning

We performed hyperparameter tuning using techniques like GridSearchCV to optimize each model's performance. This process involved systematically testing different combinations of parameters to find the best setup for each model. The tuning was particularly crucial for complex models like Neural Networks and XGBoost, where the right combination of parameters can significantly impact the model's effectiveness and efficiency.

### Conclusion
The track-level genre classification performed less optimally due to the inherent variability in songs by the same artist, peaking at 63% accuracy with XGBoost. This suggests that while machine learning can significantly aid in genre classification, the complex nature of music genres often requires more sophisticated models or multi-modal data integration to improve accuracy.

# Classification: Decade
In this phase, we implemented two distinct strategies for our decade classification tasks. The first approach involved classifying the decades of all the music tracks that we had. The second strategy was aimed at identifying the decades of the tracks in just one genre in order to explore the differences with the previous approach. Each method utilized tailored datasets and features, appropriate for classifying decades either at the non genre specific level or the genre specific level, to achieve accurate decade categorization. The genre picked for this testing was “Rock”, since it accounted for the most tracks in our dataset.


### Data Setup
Since the data was imbalanced for different genres, we believed this could be an issue as different genres developed differently throughout the years. For that reason, we downsample to have the same amount of data during training for each genre. That way, we will be able to have an "unbiased" model that will not be skewed towards the most popular genres. We also created a new variable, 'decade', by binning song release dates, which was crucial for our subsequent temporal analysis.


### Machine Learning Preparation
Same as with genre classification, we prepared our dataset for machine learning by splitting it into training and test sets—a standard practice to evaluate a model's performance on unseen data. We also converted categorical variables into a numerical format using techniques such as one-hot encoding. These transformations are crucial for training machine learning models that require numerical input, setting the stage for robust model training.


### Model Training and Evaluation
In this section of our project, we evaluated several machine learning models in order to determine the most effective approach for classifying decades when music tracks were released based on the track metadata. Each model was assessed based on its accuracy and computation time which are both crucial factors in practical applications. Below is a summary of the outcomes for each model (first value is for the non genre specific model and the second value is for the genre specific model):


#### Logistic Regression
- **Test Accuracy**: 31.03% | 32.55%
- **Computation Time**: 3m 57.9s | 2m 14.4s


#### Support Vector Machine (SVM)
- **Test Accuracy**: 29.94% | 31.12%
- **Computation Time**: 16m 48.9s |  6m 59.6s


#### Neural Network
- **Train Accuracy**: 33.72% | 41.03%
- **Test Accuracy**: 22.06% | 28.60%
- **Computation Time**: 9m 49.3s | 12m 21.0s


#### Random Forest
- **Test Accuracy**: 37.85% | 43.33%
- **Computation Time**: 18m 16.1s | 9m 41.7s


#### XGBoost
- **Test Accuracy**: 37.24% | 43.99%
- **Computation Time**: 2m 27.7s | 2m 14.0s

As we can see, all the models perform better for the genre specific dataset, which is interesting and suggests that changes affected differently to distinct genres overtime.


### Hyperparameter Tuning
We implemented a grid search to fine tune the model's hyperparameters and optimize its performance. This was crucial in identifying the most effective model settings for our specific dataset. However, as seen above, this identification seemed to not work properly. This might be due to the close similarities between the tracks among different decades. While the models do not have a high accruacy, they clearly outperfom a random model which would have an accruacy of 12.5% (8 decades). Moreover, when utilized for a single genre, it seems that the models work better, which is interesting as it might suggest that different genres developed differently throughout the years.


### Findings
While the models do not seem to work very efficiently, it is worth looking into what features are the most deterministic in predicting decades, as these woulñd be the ones that changed the most overtime.


![](../images/decade_feature_importance.png)


The Random Forest Classifier provides insights into which variables most significantly impact the determination of a track's decade, highlighting the notable changes over time. It is clear from the plot that Instrumentalness, tempo, liveness, key, major, and time signature are almost not relevant at predicting the decade of a track.This makes sense as these variables seem to be more linked to a genre rather than a decade.

### Conclusion
Our findings show that metadata from tracks is not enough to predict the decade when they were released. However, it is worth noting that the models outperform a random classifier by a great amount. This is probably due to the slight changes overtime, but accuracy improves if the models just focus on one specific genre. This is interesting moving forward as different genres seem to have developed differently from each other over time. Thus, in future exploration, it will be worth exploring tracks from different genres separately.

# Conclusion
Our findings demonstrate a promising but challenging path forward in classifying music data. While we achieved notable success in classifying artists into genres, decade classification could have performed better, highlighting the complexity of temporal influences in music. The variability within an artist's work across different songs suggests a potential for future research to refine track-level classifications. Overall, this project underscores the potential of machine learning in transforming our understanding of music through data, opening avenues for deeper exploration into the analytics of sound.

# Recommendations
Based on our project's findings and the challenges we encountered, we recommend the following strategies for future projects in music classification using machine learning:

1.	Expand Data Collection: To enhance the models' generalizability, future projects should consider expanding the dataset to include a more diverse array of artists and tracks from additional genres and less represented decades. This expansion is crucial for mitigating issues related to data imbalances and providing a richer basis for classification.
2.	Refine Data Labeling Techniques: In our project, track-level genre data was unavailable, necessitating the use of an artist's primary genre to label their songs. Further research could help investigate how an artist's style changes over time, possibly incorporating more granular and dynamic labeling methods that reflect these evolutions.
3.	Utilize Unsupervised Learning: Unsupervised learning techniques such as clustering could be explored to better understand the underlying structure of the data and identify patterns without predefined labels. This approach might also uncover interesting insights about genre and decade classifications that are not immediately apparent.

By addressing these recommendations, future projects can build on our work's foundation and push the boundaries of what's possible at the intersection of data science and music analysis.
